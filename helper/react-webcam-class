class Webcam extends React.Component<WebcamProps, WebcamState> {
 

    private canvas: HTMLCanvasElement | null = null;
  
    private ctx: CanvasRenderingContext2D | null = null;
  
    private unmounted = false;
  
    stream: MediaStream | null;
  
    video: HTMLVideoElement | null;
  
    constructor(props: WebcamProps) {
      super(props);
      this.state = {
        hasUserMedia: false
      };
      this.scanBarcode = this.scanBarcode.bind(this);
    }
  
    componentDidMount() {
      const { state, props } = this;
  
      if (!hasGetUserMedia()) {
        props.onUserMediaError("getUserMedia not supported");
  
        return;
      }
  
      if (!state.hasUserMedia) {
        this.requestUserMedia();
      }
    }
  
    componentDidUpdate(nextProps: WebcamProps) {
      const { props } = this;
  
      if (!hasGetUserMedia()) {
        props.onUserMediaError("getUserMedia not supported");
  
        return;
      }
  
      const audioConstraintsChanged =
        JSON.stringify(nextProps.audioConstraints) !==
        JSON.stringify(props.audioConstraints);
      const videoConstraintsChanged =
        JSON.stringify(nextProps.videoConstraints) !==
        JSON.stringify(props.videoConstraints);
      const minScreenshotWidthChanged =
        nextProps.minScreenshotWidth !== props.minScreenshotWidth;
      const minScreenshotHeightChanged =
        nextProps.minScreenshotHeight !== props.minScreenshotHeight;
      if (
        videoConstraintsChanged ||
        minScreenshotWidthChanged ||
        minScreenshotHeightChanged
      ) {
        this.canvas = null;
        this.ctx = null;
      }
      if (audioConstraintsChanged || videoConstraintsChanged) {
        this.stopAndCleanup();
        this.requestUserMedia();
      }
    }
  
    componentWillUnmount() {
      this.unmounted = true;
      this.stopAndCleanup();
    }
  
  scanBarcode() {
      if (window.reader) {
        let canvas = document.createElement('canvas');
        canvas.width = this.props.width;
        canvas.height = this.props.height
        let ctx = canvas.getContext('2d');
        ctx.drawImage(this.video, 0, 0, this.props.width, this.props.height);
       
        window.reader.decodeBuffer(
          ctx.getImageData(0, 0, canvas.width, canvas.height).data,
          canvas.width,
          canvas.height,
          canvas.width * 4,
          window.dynamsoft.BarcodeReader.EnumImagePixelFormat.IPF_ARGB_8888
        )
        .then((results) => {
          this.showResults(results);
        });
      }
       
    }
    showResults(results) {
      let context = this.clearOverlay();
      let txts = [];
      try {
        let localization;
        for (var i = 0; i < results.length; ++i) {
          if (results[i].LocalizationResult.ExtendedResultArray[0].Confidence >= 30) {
            txts.push(results[i].BarcodeText);
            localization = results[i].LocalizationResult;
            this.drawResult(context, localization, results[i].BarcodeText);
          }
        }
         
        this.scanBarcode();
         
      } catch (e) {
        this.scanBarcode();
      }
    }
   
  clearOverlay() {
      let context = document.getElementById('overlay').getContext('2d');
      context.clearRect(0, 0, this.props.width, this.props.height);
      context.strokeStyle = '#ff0000';
      context.lineWidth = 5;
      return context;
  }
     
  drawResult(context, localization, text) {
      context.beginPath();
      context.moveTo(localization.X1, localization.Y1);
      context.lineTo(localization.X2, localization.Y2);
      context.lineTo(localization.X3, localization.Y3);
      context.lineTo(localization.X4, localization.Y4);
      context.lineTo(localization.X1, localization.Y1);
      context.stroke();
     
      context.font = '18px Verdana';
      context.fillStyle = '#ff0000';
      let x = [ localization.X1, localization.X2, localization.X3, localization.X4 ];
      let y = [ localization.Y1, localization.Y2, localization.Y3, localization.Y4 ];
      x.sort(function(a, b) {
        return a - b;
      });
      y.sort(function(a, b) {
        return b - a;
      });
      let left = x[0];
      let top = y[0];
     
      context.fillText(text, left, top + 50);
    }
  
    private stopAndCleanup() {
      const { state } = this;
  
      if (state.hasUserMedia) {
        Webcam.stopMediaStream(this.stream);
  
        if (state.src) {
          window.URL.revokeObjectURL(state.src);
        }
      }
    }
  
    getScreenshot(screenshotDimensions?: ScreenshotDimensions) {
      const { state, props } = this;
  
      if (!state.hasUserMedia) return null;
  
      const canvas = this.getCanvas(screenshotDimensions);
      return (
        canvas &&
        canvas.toDataURL(props.screenshotFormat, props.screenshotQuality)
      );
    }
  
    getCanvas(screenshotDimensions?: ScreenshotDimensions) {
      const { state, props } = this;
  
      if (!this.video) {
        return null;
      }
  
      if (!state.hasUserMedia || !this.video.videoHeight) return null;
  
      if (!this.ctx) {
        let canvasWidth = this.video.videoWidth;
        let canvasHeight = this.video.videoHeight;
        if (!this.props.forceScreenshotSourceSize) {
          const aspectRatio = canvasWidth / canvasHeight;
  
          canvasWidth = props.minScreenshotWidth || this.video.clientWidth;
          canvasHeight = canvasWidth / aspectRatio;
  
          if (
            props.minScreenshotHeight &&
            canvasHeight < props.minScreenshotHeight
          ) {
            canvasHeight = props.minScreenshotHeight;
            canvasWidth = canvasHeight * aspectRatio;
          }
        }
  
        this.canvas = document.createElement("canvas");
        this.canvas.width = screenshotDimensions?.width ||  canvasWidth;
        this.canvas.height = screenshotDimensions?.height || canvasHeight;
        this.ctx = this.canvas.getContext("2d");
      }
  
      const { ctx, canvas } = this;
  
      if (ctx && canvas) {
        // mirror the screenshot
        if (props.mirrored) {
          ctx.translate(canvas.width, 0);
          ctx.scale(-1, 1);
        }
  
        ctx.imageSmoothingEnabled = props.imageSmoothing;
        ctx.drawImage(this.video, 0, 0, screenshotDimensions?.width || canvas.width, screenshotDimensions?.height || canvas.height);
  
        // invert mirroring
        if (props.mirrored) {
          ctx.scale(-1, 1);
          ctx.translate(-canvas.width, 0);
        }
      }
  
      return canvas;
    }
  
    private requestUserMedia() {
      const { props } = this;
  
      const sourceSelected = (
        audioConstraints: boolean | MediaTrackConstraints | undefined,
        videoConstraints: boolean | MediaTrackConstraints | undefined,
      ) => {
        const constraints: MediaStreamConstraints = {
          video: typeof videoConstraints !== "undefined" ? videoConstraints : true
        };
  
        if (props.audio) {
          constraints.audio =
            typeof audioConstraints !== "undefined" ? audioConstraints : true;
        }
  
        navigator.mediaDevices
          .getUserMedia(constraints)
          .then(stream => {
            if (this.unmounted) {
              Webcam.stopMediaStream(stream);
            } else {
              this.handleUserMedia(null, stream);
            }
          })
          .catch(e => {
            this.handleUserMedia(e);
          });
      };
  
      if ("mediaDevices" in navigator) {
        sourceSelected(props.audioConstraints, props.videoConstraints);
      } else {
        const optionalSource = (id: string | null) => ({ optional: [{ sourceId: id }] }) as MediaTrackConstraints;
  
        const constraintToSourceId = (constraint) => {
          const { deviceId } = constraint;
  
          if (typeof deviceId === "string") {
            return deviceId;
          }
  
          if (Array.isArray(deviceId) && deviceId.length > 0) {
            return deviceId[0];
          }
  
          if (typeof deviceId === "object" && deviceId.ideal) {
            return deviceId.ideal;
          }
  
          return null;
        };
  
        // @ts-ignore: deprecated api
        MediaStreamTrack.getSources(sources => {
          let audioSource: string | null = null;
          let videoSource: string | null = null;
  
          sources.forEach((source: MediaStreamTrack) => {
            if (source.kind === "audio") {
              audioSource = source.id;
            } else if (source.kind === "video") {
              videoSource = source.id;
            }
          });
  
          const audioSourceId = constraintToSourceId(props.audioConstraints);
          if (audioSourceId) {
            audioSource = audioSourceId;
          }
  
          const videoSourceId = constraintToSourceId(props.videoConstraints);
          if (videoSourceId) {
            videoSource = videoSourceId;
          }
  
          sourceSelected(
            optionalSource(audioSource),
            optionalSource(videoSource)
          );
        });
      }
    }
  
    private handleUserMedia(err, stream?: MediaStream) {
      const { props } = this;
  
      if (err || !stream) {
        this.setState({ hasUserMedia: false });
        props.onUserMediaError(err);
  
        return;
      }
  
      this.stream = stream;
  
      try {
        if (this.video) {
          this.video.srcObject = stream;
        }
        this.setState({ hasUserMedia: true });
      } catch (error) {
        this.setState({
          hasUserMedia: true,
          src: window.URL.createObjectURL(stream)
        });
      }
  
      props.onUserMedia(stream);
    }
  
    render() {
      const { state, props } = this;
  
      const {
        audio,
        forceScreenshotSourceSize,
        onUserMedia,
        onUserMediaError,
        screenshotFormat,
        screenshotQuality,
        minScreenshotWidth,
        minScreenshotHeight,
        audioConstraints,
        videoConstraints,
        imageSmoothing,
        mirrored,
        style = {},
        ...rest
      } = props;
  
      const videoStyle = mirrored ? { ...style, transform: `${style.transform || ""} scaleX(-1)` } : style;
  
      return (
      <div id='videoview' width={this.props.width} height={this.props.height}>
          <button onClick={this.scanBarcode}>Scan Barcodes</button>
          <video
              autoPlay
              src={state.src}
              muted={!audio}
              playsInline
              ref={ref => {
              this.video = ref;
              }}
              style={videoStyle}
              {...rest}
          />
                <canvas id="overlay" width={this.props.width} height={this.props.height}></canvas>
        </div>
      );
    }
  }